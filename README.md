# Chronos-Atlas

This is the final, comprehensive, and consolidated blueprint for your "Chronos Atlas" project. I have organized everything into three logically separated Markdown files for easy saving, review, and execution planning:
 * ARCHITECTURE_BLUEPRINT.md: The core technical plan and database design.
 * EXECUTION_ROADMAP.md: The phased implementation strategy.
 * DATA_FLOW_AND_SCALING.md: The operational logic and performance rationale. 
1. ARCHITECTURE_BLUEPRINT.md
üöÄ "Chronos Atlas" Technical Architecture
This document outlines the definitive stack, components, and optimized data model for the project.
1.1 The Optimized Technology Stack
| Layer | Component | Technology | Rationale |
|---|---|---|---|
| Backend Language | Python üêç | Versatile, great for ETL and API logic. |  |
| Web Framework | Django | Provides a complete, secure structure (ORM, Admin, Auth). |  |
| Primary Database | PostgreSQL üêò | Crucial for performance. Superior time-series indexing and relational integrity. |  |
| API Layer | GraphQL (Graphene-Django) | Efficient, flexible data fetching for the complex Timeline View. |  |
| Caching/Broker | Redis | In-memory cache for API results; message broker for Celery tasks. |  |
| Background Jobs | Celery | Runs long-lived ETL/Data-update jobs asynchronously. |  |
| Data Source | Wikidata (via SPARQLWrapper) | Provides structured, open historical data. |  |
| Deployment Standard | Docker/Docker Compose | Ensures consistent, portable environments. |  |
1.2 The Refined Data Model (PostgreSQL Schema)
The schema is built for speed, relationship complexity, and future filtering needs.
A. Core Entities
| Table | Field | Data Type | Purpose & Optimization |
|---|---|---|---|
| Figure | id, slug, name, summary | PK, Char, Char, Text | Core biographical data. |
|  | wikidata_id | CharField (Unique) | Essential for mapping and ETL updates. |
|  | birth_date, death_date | DateField, DateField (Nullable) | Precise dates. |
|  | normalized_birth_year | IntegerField (Indexed) | CRITICAL: Indexed for extremely fast timeline range queries. |
|  | normalized_death_year | IntegerField (Indexed, Nullable) | CRITICAL: Indexed for extremely fast timeline range queries. |
|  | instance_of_QIDs | ArrayField(CharField) | Stores raw Wikidata identifiers for flexible technical filtering. |
| WorkOrEvent | id, figure (FK), title | PK, FK, Char | Timeline milestones. |
|  | event_date | DateField | Date the event occurred. |
|  | event_type | CharField | Categorizes the milestone: WORK, LIFE_EVENT, INVENTION, etc. |
B. Relational and Taxonomy Tables
| Table | Field | Relationship Rationale |
|---|---|---|
| Influence | id | Primary key for the relationship itself. |
|  | subject (FK to Figure) | The person the relationship is about (e.g., The one who was influenced). |
|  | object (FK to Figure) | The person related to the subject (e.g., The influencer). |
|  | relationship_type | Explicit type: INFLUENCED_BY, STUDENT_OF, CONTEMPORARY_OF. Allows efficient querying in both directions. |
| Field | id, name (Unique) | High-level categories (e.g., 'Physics', 'Literature'). |
| Occupation | id, name (Unique) | Detailed, searchable occupations (e.g., 'Theoretical Physicist'). |
| M2M Join Tables | (Between Figure and Field/Occupation) | Allows one figure to be associated with multiple categories/roles for flexible filtering. |
2. EXECUTION_ROADMAP.md
üó∫Ô∏è "Chronos Atlas" Phased Implementation Roadmap
This plan divides the project into manageable phases, prioritizing the MVP first, then scaling performance and features.
Phase 0: Foundation (Backend Core)
| Milestone | Deliverables | Key Technical Focus |
|---|---|---|
| 0.1 Setup & Schema | Docker environment for 3 services (Django, PG, Redis). Define all Django Models. | Docker/Containerization. |
| 0.2 Performance Layer | Apply all PostgreSQL Time-Series Indexes (GiST/BRIN) on normalized_year fields. | Database Optimization. |
| 0.3 ETL Proof-of-Concept | Working Django Management Command using SPARQLWrapper. Implements date transformation logic to populate normalized_year. Load 1,000+ test figures. | Data Integrity & ETL Scripting. |
| 0.4 API Boilerplate | Setup graphene-django and define all base types (FigureType, etc.). | GraphQL Schema Definition. |
Phase 1: MVP (Minimum Viable Product)
| Milestone | Deliverables | Key Technical Focus |
|---|---|---|
| 1.1 Master Timeline API | Fully functional timelineFigures GraphQL Resolver accepting startYear/endYear. | Optimized PG Query Logic. |
| 1.2 Frontend & Visualization | Basic frontend setup. Interactive, horizontal Timeline View rendering figure life-spans. | Visualization Library Implementation. |
| 1.3 Figure Detail View | Profile page with the figure's bio, works, and the Vertical Works/Events Timeline. | GraphQL Relational Resolving. |
| 1.4 Launch | Basic search, clean styling, and routing. MVP is ready for initial external review. | Core UX/UI. |
Phase 2: Performance & Graph Features
| Milestone | Deliverables | Key Technical Focus |
|---|---|---|
| 2.1 Core Caching | Implement Redis Caching for the high-traffic timelineFigures Resolver. | Performance & Redis Integration. |
| 2.2 Asynchronous ETL | Convert ETL script to a scheduled Celery background task. | Celery Setup & Task Offloading. |
| 2.3 Relational Features | Load Influence and Occupation data. Update GraphQL to expose these complex relationships. | Advanced ETL & Data Modeling. |
| 2.4 Filtering & UX | Implement dynamic filtering based on Field and Occupation. Add final styling. | Frontend State Management. |
Phase 3: Production Ready (V1.0)
| Milestone | Deliverables | Key Technical Focus |
|---|---|---|
| 3.1 Full-Scale Load | Complete ingestion of all target figures (10,000+). | Database Monitoring & Tuning. |
| 3.2 Hardening | Implement API Rate Limiting, security, and backup procedures. | Security & Stability. |
| 3.3 Production Deployment | Deploy to a cloud environment (e.g., AWS/GCP) using Docker. | CI/CD Pipeline. |
| 3.4 Publish | "Chronos Atlas" V1.0 is launched. | Final QA & Maintenance Plan. |
3. DATA_FLOW_AND_SCALING.md
üåä "Chronos Atlas" Data Flow and Scaling Rationale
This document clarifies how data moves through the system and justifies the database choice for scaling.
3.1 Data Flow Diagram (Operational Logic)
| Cycle | Step | Node/Component | Action/Flow |
|---|---|---|---|
| Ingestion | 1. Schedule | Celery Beat \rightarrow Redis | Sends the ETL task to the message queue. |
| (Async ETL) | 2. Extract | Celery Worker \rightarrow SPARQLWrapper | Runs Python code to query Wikidata. |
|  | 3. Transform | Django Command | Cleans data, calculates normalized_year. |
|  | 4. Load | Django Command \rightarrow PostgreSQL | Upserts clean data; PG applies time-series indexes. |
| Serving | 1. Request | User Browser \rightarrow Django Server | Sends specific GraphQL query (e.g., timelineFigures(startYear: 1600)). |
| (Real-time) | 2. Cache Check | Graphene Resolver \rightarrow Redis | Checks if the query result exists in Redis. |
|  | 3. Database Query | Graphene Resolver \rightarrow PostgreSQL | (Cache Miss) Executes fast indexed query for the timeline range. |
|  | 4. Cache Write | Graphene Resolver \rightarrow Redis | (Cache Miss) Stores the result back into Redis. |
|  | 5. Response | Graphene Resolver \rightarrow User Browser | Returns the final JSON payload. |
3.2 Scaling Rationale: PostgreSQL is Key
The choice of PostgreSQL over NoSQL (like MongoDB) is a deliberate scaling strategy for this project.
| Scaling Challenge | PostgreSQL Solution | Why NoSQL is Inadequate Here |
|---|---|---|
| Timeline Query Speed | Uses Indexed Integer (normalized_year) fields combined with GiST/BRIN time-series indexing. | NoSQL's general B-tree indexes struggle with the vast, overlapping range queries required for a historical timeline. |
| Relational Complexity | Native, Fast JOINs enforce data integrity (Foreign Keys) and allow the GraphQL API to efficiently link Figure to Work and Influence in a single query. | NoSQL requires complex, application-level lookups ($lookup or multiple requests) to stitch relationships, which is slower and riskier. |
| ETL Management | Separated the long-running ETL from the web server using Celery/Redis. | This issue is solved by the application architecture (Celery), not the database type. PG is highly durable for the final write. |
| Future Read Scaling | Easily scaled by deploying multiple Read Replicas to distribute the high volume of user read traffic. | (No disadvantage here, but PG can match NoSQL's horizontal read scaling needs). |
The schema's design is future-proof because it prioritizes performance on the core chronological feature and uses PostgreSQL's transactional integrity for data reliability.
